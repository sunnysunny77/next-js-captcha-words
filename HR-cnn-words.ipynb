{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68ea08b1-c4d9-4007-800d-df353c8e05f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-09 14:00:09.825781: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1757397609.836699  115472 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1757397609.840121  115472 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1757397609.849162  115472 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757397609.849173  115472 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757397609.849174  115472 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757397609.849176  115472 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-09-09 14:00:09.852222: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "I0000 00:00:1757397642.951807  115472 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 895 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050, pci bus id: 0000:09:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import CategoricalFocalCrossentropy\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import cv2\n",
    "\n",
    "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "tf.config.optimizer.set_jit(True)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_SAMPLES_PER_WORD = 500   \n",
    "WORDS = ['MISS', 'THEY', 'THIS', 'WEST', 'ALSO', 'BEEN', 'DAYS', 'EVEN', 'FILM', 'FROM',\n",
    "         'GOOD', 'HAVE', 'INTO', 'LAST', 'LIFE', 'LIKE', 'MADE', 'MAKE', 'MANY', 'MORE',\n",
    "         'MOST', 'MUCH', 'MUST', 'NEED', 'ONLY', 'OVER', 'PART', 'PLAY', 'SAID', 'SOME',\n",
    "         'SUCH', 'TAKE', 'THAN', 'THAT', 'THEM', 'THEY', 'THIS', 'TIME', 'USED', 'WEEK',\n",
    "         'WELL', 'WERE', 'WHAT', 'WHEN', 'WILL', 'WITH', 'WORK', 'YEAR', 'YOUR']\n",
    "WORD_INDEX = {w: i for i, w in enumerate(WORDS)}\n",
    "NUM_WORDS = len(WORDS)\n",
    "MAX_LETTERS = max(len(w) for w in WORDS)\n",
    "IMG_HEIGHT = 28\n",
    "IMG_WIDTH = IMG_HEIGHT * MAX_LETTERS \n",
    "\n",
    "df_train = pd.read_csv(\"./emnist-byclass-train.csv\", header=None)\n",
    "df_test  = pd.read_csv(\"./emnist-byclass-test.csv\", header=None)\n",
    "\n",
    "X_train = df_train.drop(columns=[0]).to_numpy()\n",
    "y_train = df_train[0].to_numpy()\n",
    "X_test = df_test.drop(columns=[0]).to_numpy()\n",
    "y_test = df_test[0].to_numpy()\n",
    "\n",
    "train_mask = (y_train >= 10) & (y_train <= 35)\n",
    "test_mask  = (y_test >= 10) & (y_test <= 35)\n",
    "\n",
    "X_train = X_train[train_mask]\n",
    "y_train = y_train[train_mask] - 10  \n",
    "X_test = X_test[test_mask]\n",
    "y_test = y_test[test_mask] - 10\n",
    "\n",
    "X_train = X_train.reshape(-1, 28, 28)\n",
    "X_test  = X_test.reshape(-1, 28, 28)\n",
    "\n",
    "def fix_orientation(images):\n",
    "    return np.flip(np.rot90(images, k=3, axes=(1, 2)), axis=2)\n",
    "\n",
    "X_train = fix_orientation(X_train)\n",
    "X_test = fix_orientation(X_test)\n",
    "\n",
    "def generate_word(word_list, letter_images, letter_labels, n_samples_per_word):\n",
    "    X_words, y_words = [], []\n",
    "    for word in word_list:\n",
    "        for _ in range(n_samples_per_word):\n",
    "            imgs = []\n",
    "            for c in word.upper():\n",
    "                idx = ord(c) - ord('A')\n",
    "                candidates = np.where(letter_labels == idx)[0]\n",
    "                img = letter_images[np.random.choice(candidates)]\n",
    "                imgs.append(img)\n",
    "            word_img = np.hstack(imgs)\n",
    "            word_img = cv2.resize(word_img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "            X_words.append(word_img[..., np.newaxis].astype(np.float32) / 255.0)\n",
    "            y_words.append(WORD_INDEX[word.upper()])\n",
    "    X_words = np.array(X_words)\n",
    "    y_words = to_categorical(y_words, num_classes=NUM_WORDS)\n",
    "    return X_words, y_words\n",
    "\n",
    "X_words, y_words = generate_word(WORDS, X_train, y_train, NUM_SAMPLES_PER_WORD)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_words, y_words, test_size=0.1, random_state=42, stratify=y_words.argmax(axis=1)\n",
    ")\n",
    "\n",
    "augmentation = Sequential([\n",
    "    layers.RandomRotation(0.05),\n",
    "    layers.RandomTranslation(0.05, 0.05),\n",
    "    layers.RandomZoom(0.05),\n",
    "    layers.RandomContrast(0.05)\n",
    "])\n",
    "\n",
    "def prepare_augmentation(x, y):\n",
    "    x = augmentation(x, training=True)\n",
    "    return x, y\n",
    "\n",
    "train_ds = (\n",
    "    Dataset.from_tensor_slices((X_train, y_train))\n",
    "    .shuffle(2048)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .map(prepare_augmentation, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "val_ds = (\n",
    "    Dataset.from_tensor_slices((X_val, y_val))\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6863f89-c937-4d37-ad56-a887541f2e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 1))\n",
    "\n",
    "x = layers.Conv2D(16, 3, strides=1, padding=\"same\", use_bias=False)(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Conv2D(32, 3, strides=1, padding=\"same\", use_bias=False)(x)\n",
    "\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Conv2D(32, 3, strides=2, padding=\"same\", use_bias=False)(x)\n",
    "x = layers.SpatialDropout2D(0.1)(x)\n",
    "\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Conv2D(32, 3, strides=1, padding=\"same\", use_bias=False)(x)\n",
    "\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Conv2D(32, 3, strides=1, padding=\"same\", use_bias=False)(x)\n",
    "\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Conv2D(64, 3, strides=2, padding=\"same\", use_bias=False)(x)\n",
    "x = layers.SpatialDropout2D(0.1)(x)\n",
    "\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Conv2D(64, 3, strides=1, padding=\"same\", use_bias=False)(x)\n",
    "\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Conv2D(64, 3, strides=1, padding=\"same\", use_bias=False)(x)\n",
    "\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Conv2D(128, 3, strides=2, padding=\"same\", use_bias=False)(x)\n",
    "x = layers.SpatialDropout2D(0.15)(x)\n",
    "\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Conv2D(128, 3, strides=1, padding=\"same\", use_bias=False)(x)\n",
    "\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Conv2D(128, 3, strides=1, padding=\"same\", use_bias=False)(x)\n",
    "\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Dense(128, use_bias=False)(x)\n",
    "\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "outputs = layers.Dense(NUM_WORDS, activation=\"softmax\", dtype=\"float32\")(x)\n",
    "\n",
    "model = models.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ddf1358-0b4c-4aa5-b7f7-7b3b1b75ec4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1757397657.555851  115593 service.cc:152] XLA service 0x708aac008130 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1757397657.555867  115593 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3050, Compute Capability 8.6\n",
      "I0000 00:00:1757397657.563400  115593 cuda_dnn.cc:529] Loaded cuDNN version 91200\n",
      "I0000 00:00:1757397657.609719  115593 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2025-09-09 14:00:59.538547: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-09 14:01:01.430765: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3733', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-09-09 14:01:01.721775: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3778', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-09-09 14:01:01.779430: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6177', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-09-09 14:01:02.260052: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4830', 560 bytes spill stores, 560 bytes spill loads\n",
      "\n",
      "2025-09-09 14:01:02.515791: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4830', 44 bytes spill stores, 44 bytes spill loads\n",
      "\n",
      "2025-09-09 14:01:02.937214: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4830', 160 bytes spill stores, 160 bytes spill loads\n",
      "\n",
      "2025-09-09 14:01:03.465578: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3778', 332 bytes spill stores, 332 bytes spill loads\n",
      "\n",
      "2025-09-09 14:01:04.062992: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4830', 56 bytes spill stores, 56 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m171/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1533 - loss: 0.8310"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-09 14:01:28.944179: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4830', 108 bytes spill stores, 108 bytes spill loads\n",
      "\n",
      "2025-09-09 14:01:29.275354: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6204', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.1558 - loss: 0.8283"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-09 14:01:45.801781: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_29', 44 bytes spill stores, 44 bytes spill loads\n",
      "\n",
      "2025-09-09 14:01:46.761147: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_380', 28 bytes spill stores, 28 bytes spill loads\n",
      "\n",
      "2025-09-09 14:01:46.849248: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_380', 68 bytes spill stores, 68 bytes spill loads\n",
      "\n",
      "2025-09-09 14:01:48.525691: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_380', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 155ms/step - accuracy: 0.3720 - loss: 0.6046 - val_accuracy: 0.0273 - val_loss: 0.9928 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9108 - loss: 0.2098 - val_accuracy: 0.0482 - val_loss: 0.9655 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9756 - loss: 0.1747 - val_accuracy: 0.8367 - val_loss: 0.3247 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9867 - loss: 0.1637 - val_accuracy: 0.9967 - val_loss: 0.1508 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9911 - loss: 0.1581 - val_accuracy: 0.9971 - val_loss: 0.1479 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9937 - loss: 0.1545 - val_accuracy: 0.9951 - val_loss: 0.1513 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9942 - loss: 0.1523 - val_accuracy: 0.9943 - val_loss: 0.1498 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9959 - loss: 0.1500 - val_accuracy: 0.9992 - val_loss: 0.1423 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9964 - loss: 0.1481 - val_accuracy: 0.9959 - val_loss: 0.1478 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9967 - loss: 0.1478 - val_accuracy: 0.9980 - val_loss: 0.1441 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9969 - loss: 0.1464 - val_accuracy: 0.9976 - val_loss: 0.1421 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9976 - loss: 0.1454 - val_accuracy: 0.9988 - val_loss: 0.1390 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9974 - loss: 0.1449 - val_accuracy: 0.9976 - val_loss: 0.1419 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9978 - loss: 0.1444 - val_accuracy: 0.9967 - val_loss: 0.1517 - learning_rate: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m169/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9983 - loss: 0.1439\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9980 - loss: 0.1436 - val_accuracy: 0.9988 - val_loss: 0.1389 - learning_rate: 0.0010\n",
      "Epoch 16/30\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9987 - loss: 0.1415 - val_accuracy: 0.9996 - val_loss: 0.1360 - learning_rate: 5.0000e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9986 - loss: 0.1406 - val_accuracy: 0.9996 - val_loss: 0.1362 - learning_rate: 5.0000e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9991 - loss: 0.1404 - val_accuracy: 0.9992 - val_loss: 0.1362 - learning_rate: 5.0000e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9992 - loss: 0.1404 - val_accuracy: 0.9992 - val_loss: 0.1352 - learning_rate: 5.0000e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9993 - loss: 0.1401 - val_accuracy: 0.9988 - val_loss: 0.1359 - learning_rate: 5.0000e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9992 - loss: 0.1402 - val_accuracy: 0.9992 - val_loss: 0.1353 - learning_rate: 5.0000e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9991 - loss: 0.1401\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9991 - loss: 0.1399 - val_accuracy: 0.9988 - val_loss: 0.1365 - learning_rate: 5.0000e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9993 - loss: 0.1391 - val_accuracy: 0.9992 - val_loss: 0.1347 - learning_rate: 2.5000e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9993 - loss: 0.1388 - val_accuracy: 0.9988 - val_loss: 0.1349 - learning_rate: 2.5000e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9991 - loss: 0.1388 - val_accuracy: 0.9988 - val_loss: 0.1339 - learning_rate: 2.5000e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9995 - loss: 0.1386 - val_accuracy: 0.9988 - val_loss: 0.1344 - learning_rate: 2.5000e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9995 - loss: 0.1384 - val_accuracy: 0.9988 - val_loss: 0.1344 - learning_rate: 2.5000e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m172/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9994 - loss: 0.1386\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9992 - loss: 0.1385 - val_accuracy: 0.9996 - val_loss: 0.1340 - learning_rate: 2.5000e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9997 - loss: 0.1377 - val_accuracy: 0.9992 - val_loss: 0.1334 - learning_rate: 1.2500e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9995 - loss: 0.1378 - val_accuracy: 0.9996 - val_loss: 0.1336 - learning_rate: 1.2500e-04\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step\n",
      "Validation Accuracy: 0.9991836734693877\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=AdamW(learning_rate=1e-3, weight_decay=1e-4),\n",
    "    loss=CategoricalFocalCrossentropy(gamma=2.0, from_logits=False, label_smoothing=0.1),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=30,\n",
    "    callbacks=[\n",
    "        ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6, verbose=1),\n",
    "        EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "y_val_pred = model.predict(val_ds)\n",
    "y_val_labels = y_val.argmax(axis=1)\n",
    "y_pred_labels = y_val_pred.argmax(axis=1)\n",
    "\n",
    "accuracy = accuracy_score(y_val_labels, y_pred_labels)\n",
    "print(\"Validation Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a86edb6-2f5c-4c7a-924a-44f0fd026a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: HR/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: HR/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, \"HR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f78797-836d-44a0-a27c-0aee02217e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-09 14:03:42.199695: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1757397822.211191  118282 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1757397822.214669  118282 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1757397822.223603  118282 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757397822.223618  118282 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757397822.223622  118282 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757397822.223628  118282 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[32m🌲 Try \u001b[0m\u001b[34mhttps://ydf.readthedocs.io\u001b[0m\u001b[32m, the successor of TensorFlow Decision Forests with more features and faster training!\u001b[0m\n",
      "/home/dan/tf-gpu-env/lib/python3.11/site-packages/tensorflow_hub/__init__.py:61: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import parse_version\n",
      "I0000 00:00:1757397824.924260  118282 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 114 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050, pci bus id: 0000:09:00.0, compute capability: 8.6\n",
      "I0000 00:00:1757397825.010084  118282 cuda_executor.cc:479] failed to allocate 114.75MiB (120324096 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1757397825.010164  118282 cuda_executor.cc:479] failed to allocate 103.27MiB (108291840 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1757397825.010219  118282 cuda_executor.cc:479] failed to allocate 92.95MiB (97462784 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1757397825.196226  118282 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1757397825.196346  118282 single_machine.cc:374] Starting new session\n",
      "I0000 00:00:1757397825.201997  118282 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 114 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050, pci bus id: 0000:09:00.0, compute capability: 8.6\n",
      "weight StatefulPartitionedCall/functional_1_1/conv2d_1/convolution/Cast with shape (3, 3, 1, 16) and dtype float16 was auto converted to the type float32\n",
      "weight StatefulPartitionedCall/functional_1_1/conv2d_1_2/convolution/Cast with shape (3, 3, 16, 32) and dtype float16 was auto converted to the type float32\n",
      "weight StatefulPartitionedCall/functional_1_1/conv2d_2_1/convolution/Cast with shape (3, 3, 32, 32) and dtype float16 was auto converted to the type float32\n",
      "weight StatefulPartitionedCall/functional_1_1/conv2d_3_1/convolution/Cast with shape (3, 3, 32, 32) and dtype float16 was auto converted to the type float32\n",
      "weight StatefulPartitionedCall/functional_1_1/conv2d_4_1/convolution/Cast with shape (3, 3, 32, 32) and dtype float16 was auto converted to the type float32\n",
      "weight StatefulPartitionedCall/functional_1_1/conv2d_5_1/convolution/Cast with shape (3, 3, 32, 64) and dtype float16 was auto converted to the type float32\n",
      "weight StatefulPartitionedCall/functional_1_1/conv2d_6_1/convolution/Cast with shape (3, 3, 64, 64) and dtype float16 was auto converted to the type float32\n",
      "weight StatefulPartitionedCall/functional_1_1/conv2d_7_1/convolution/Cast with shape (3, 3, 64, 64) and dtype float16 was auto converted to the type float32\n",
      "weight StatefulPartitionedCall/functional_1_1/conv2d_8_1/convolution/Cast with shape (3, 3, 64, 128) and dtype float16 was auto converted to the type float32\n",
      "weight StatefulPartitionedCall/functional_1_1/conv2d_9_1/convolution/Cast with shape (3, 3, 128, 128) and dtype float16 was auto converted to the type float32\n",
      "weight StatefulPartitionedCall/functional_1_1/conv2d_10_1/convolution/Cast with shape (3, 3, 128, 128) and dtype float16 was auto converted to the type float32\n",
      "weight StatefulPartitionedCall/functional_1_1/dense_1/Cast/Cast with shape (128, 128) and dtype float16 was auto converted to the type float32\n"
     ]
    }
   ],
   "source": [
    "!tensorflowjs_converter --input_format=tf_saved_model --output_format=tfjs_graph_model HR tfjs_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dda56f1-b43a-49d2-863a-6e52e3ed9e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
